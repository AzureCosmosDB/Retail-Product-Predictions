{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "! pip install numpy\n",
        "! pip install openai==1.2.3\n",
        "! pip install python-dotenv\n",
        "! pip install prettytable\n",
        "\n",
        "! pip install azure-cosmos\n",
        "! pip install azure-core\n",
        "! pip install aiohttp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import dotenv_values\n",
        "from openai import AzureOpenAI\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "from azure.cosmos import CosmosClient\n",
        "from azure.cosmos import PartitionKey, exceptions\n",
        "from azure.cosmos import ThroughputProperties\n",
        "\n",
        "import asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1712007427712
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "env_name = \"../myconfig.env\" \n",
        "config = dotenv_values(env_name)\n",
        "\n",
        "# Cosmos Client\n",
        "cosmos_endpoint = config['cosmos_endpoint']\n",
        "cosmos_key = config['cosmos_key']\n",
        "database_name = config['cosmos_database']\n",
        "actual_ratings_name = config['cosmos_actual_ratings']\n",
        "predicted_ratings_name = config['cosmos_predicted_ratings']\n",
        "product_catalog_name = config['cosmos_product_catalog']\n",
        "\n",
        "cosmos_client = CosmosClient(cosmos_endpoint, cosmos_key)\n",
        "\n",
        "# Collection references\n",
        "database = cosmos_client.get_database_client(database_name)\n",
        "product_catalog_container = database.get_container_client(product_catalog_name)\n",
        "actual_ratings_container = database.get_container_client(actual_ratings_name)\n",
        "predicted_ratings_container = database.get_container_client(predicted_ratings_name)\n",
        "\n",
        "# OpenAI\n",
        "openai_type = config['openai_type']\n",
        "openai_key = config['openai_key']\n",
        "openai_base = config['openai_endpoint']\n",
        "openai_version = config['openai_version']\n",
        "openai_embeddings = config['openai_embeddings_deployment']\n",
        "\n",
        "openai_client = AzureOpenAI(\n",
        "    api_key=openai_key,\n",
        "    api_version=openai_version,\n",
        "    azure_endpoint = openai_base\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1711055304916
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def generate_azure_openai_embeddings(text):\n",
        "    \n",
        "    response = openai_client.embeddings.create(\n",
        "        input = text, \n",
        "        model = openai_embeddings\n",
        "    )\n",
        "    \n",
        "    embeddings = response.data[0].embedding\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_vector_search_results(results):\n",
        "    \n",
        "    print(\"---------Vector Search Results: --------\")\n",
        "\n",
        "    # Define the table\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Product Id\", \"Name\", \"Price\", \"Similarity Score\", \"Rating\"]\n",
        "\n",
        "    # Add rows to the table\n",
        "    for product in results:\n",
        "        table.add_row([\n",
        "            product['Id'],\n",
        "            product['Name'],\n",
        "            product['Price'],\n",
        "            product['SimilarityScore'],\n",
        "            product['Rating']\n",
        "        ])\n",
        "\n",
        "    # Print the table\n",
        "    print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_predictions_from_product_page(results):\n",
        "    print(\"\\n--------Current Page Results: ---------\")\n",
        "\n",
        "    # Define the table\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Product Id\", \"Name\", \"Price\", \"Rating\"]\n",
        "\n",
        "    # Add rows to the table\n",
        "    for product in results:\n",
        "        table.add_row([\n",
        "            product['Id'],\n",
        "            product['Name'],\n",
        "            product['Price'],\n",
        "            product['Rating']\n",
        "        ])\n",
        "\n",
        "    # Print the table\n",
        "    print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Product Recommendation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predictions_from_current_product_page(user_id, current_product_id, num_results=4):\n",
        "    \"\"\"\n",
        "    This function displays predicted products for this user excluding the current product.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get the predicted products for the user\n",
        "    predicted_results = predicted_ratings_container.read_item(item=user_id, partition_key=user_id)\n",
        "    \n",
        "    # Remove all but the number of items in num_results from the results\n",
        "    predicted_results['Predictions'] = predicted_results['Predictions'][:num_results]\n",
        "    \n",
        "    # Remove the current product from the list\n",
        "    user_predicted_products = [prediction for prediction in predicted_results['Predictions']\n",
        "        if prediction['ProductId'] != current_product_id]\n",
        "    \n",
        "    predicted_products = []\n",
        "\n",
        "    # Look up recommended products maintaining order of predicted ratings\n",
        "    for item in user_predicted_products:\n",
        "        product_id = item['ProductId']\n",
        "        product = product_catalog_container.read_item(item=product_id, partition_key=product_id)\n",
        "        if product:\n",
        "            # remove the Embedding property from the product\n",
        "            product.pop('Embedding')\n",
        "            predicted_products.append(product)\n",
        "            predicted_products[-1]['Rating'] = item['Rating']\n",
        "\n",
        "    predicted_products = list(predicted_products)\n",
        "\n",
        "    return predicted_products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the Function above on predictions excluding the current product on page\n",
        "user_id = \"1\"\n",
        "product_id = \"92\" # Shaun White snowboard\n",
        "num_results = 10\n",
        "\n",
        "# Predictions excluding the current product on page\n",
        "on_page_predictions = predictions_from_current_product_page(user_id, product_id, num_results)\n",
        "\n",
        "print_predictions_from_product_page(on_page_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vector_search(user_prompt, product_ids, num_results=10):\n",
        "    \n",
        "    prompt_embedding = generate_azure_openai_embeddings(user_prompt)\n",
        "    \n",
        "    results = product_catalog_container.query_items(\n",
        "        query='''\n",
        "            SELECT TOP @num_results \n",
        "                c.id, c.Id, c.Type, c.Brand, c.Name, c.Description, c.Price, VectorDistance(c.Embedding, @embedding) AS SimilarityScore\n",
        "            FROM c WHERE ARRAY_CONTAINS(@product_ids, c.id) \n",
        "            ORDER BY VectorDistance(c.Embedding, @embedding)''',\n",
        "        parameters=[\n",
        "            {\"name\": \"@product_ids\", \"value\": product_ids},\n",
        "            {\"name\": \"@embedding\", \"value\": prompt_embedding}, \n",
        "            {\"name\": \"@num_results\", \"value\": num_results}\n",
        "        ],\n",
        "        enable_cross_partition_query=True)\n",
        "   \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predictions_from_vector_search(user_id, user_prompt, num_results=10):\n",
        "    \"\"\" \n",
        "    This function takes a user prompt search for products and returns products that are predicted for the user. \n",
        "    \"\"\"\n",
        "\n",
        "    # Get the predicted products for the user\n",
        "    predicted_products = predicted_ratings_container.read_item(item=user_id, partition_key=user_id)\n",
        "    \n",
        "    # Convert to a dictionary\n",
        "    predicted_products = {prediction['ProductId']: prediction for prediction in predicted_products['Predictions']}\n",
        "    \n",
        "    # Filter criteria to include product ids from the predicted products\n",
        "    product_ids = list(predicted_products.keys())\n",
        "\n",
        "    # Call the Cosmos DB NoSQL vector search function\n",
        "    results = vector_search(user_prompt, product_ids, num_results)\n",
        "    \n",
        "    filtered_vector_search = list(results)\n",
        "\n",
        "    # Add the Rating field to the documents in filtered_vector_search\n",
        "    for item in filtered_vector_search:\n",
        "        product_id = item['id']\n",
        "        if product_id in predicted_products:\n",
        "            item['Rating'] = predicted_products[product_id]['Rating']\n",
        "\n",
        "    # Remove the top vector search result. Add back after sorting by rating\n",
        "    top_vector_result = filtered_vector_search.pop(0)\n",
        "    \n",
        "    # Sort the remaining results by rating\n",
        "    sorted_vector_search = sorted(filtered_vector_search, key=lambda x: x['Rating'], reverse=True)  \n",
        "\n",
        "    # Insert the top result at the beginning of the list\n",
        "    sorted_vector_search.insert(0, top_vector_result)\n",
        "\n",
        "    return sorted_vector_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------Vector Search Results: --------\n",
            "+------------+------------------------------+--------+---------------------+--------------------+\n",
            "| Product Id |             Name             | Price  |   Similarity Score  |       Rating       |\n",
            "+------------+------------------------------+--------+---------------------+--------------------+\n",
            "|     92     |  Shaun White Powder Groomer  | 449.99 | 0.43047156333434977 | 6.279876708984375  |\n",
            "|     22     |    Venture 2022 Snowboard    |  499   |  0.3629531261503729 | 6.241421222686768  |\n",
            "|     62     |    Shadow Black Snowboard    |  379   | 0.36706966912712613 | 5.962630271911621  |\n",
            "|     53     |    Raven Swift Snowboard     |  349   |  0.3609885640374669 | 5.821575164794922  |\n",
            "|     73     |   Omni-Snow Dual Snowboard   | 289.99 |  0.404109018011247  | 5.8155903816223145 |\n",
            "|     60     | SummitRider Snowboard Boots  |  249   |  0.3573901028293825 | 5.6328301429748535 |\n",
            "|     12     |     Powder Pro Snowboard     |  399   |  0.3807208587556782 | 5.5409369468688965 |\n",
            "|     83     | Blizzard Freestyle Snowboard |  379   |  0.3738995546138773 | 5.454874038696289  |\n",
            "|     43     |   Glacier Frost Snowboard    | 419.99 |  0.3901342192281589 | 5.3842315673828125 |\n",
            "|     5      |   Blizzard Rider Snowboard   | 299.99 |  0.3858993974076597 | 4.8326568603515625 |\n",
            "+------------+------------------------------+--------+---------------------+--------------------+\n"
          ]
        }
      ],
      "source": [
        "# Test the function above for filtering vector search results with predicted products\n",
        "\n",
        "user_prompt = \"I want to snowboard like an Olympic Champion\" #\"Snowboards used by Olympic champions\"\n",
        "user_id = \"189\"\n",
        "num_results = 10\n",
        "\n",
        "# Vector Search with Predictions\n",
        "vector_search_with_predictions = predictions_from_vector_search(user_id, user_prompt, num_results)\n",
        "print_vector_search_results(vector_search_with_predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
