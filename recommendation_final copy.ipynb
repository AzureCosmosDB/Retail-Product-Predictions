{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "! pip install numpy\n",
        "! pip install openai==1.2.3\n",
        "! pip install pymongo\n",
        "! pip install python-dotenv\n",
        "! pip install tenacity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1712007427712
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "import pymongo\n",
        "\n",
        "from dotenv import dotenv_values\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "env_name = \"myconfig.env\" \n",
        "config = dotenv_values(env_name)\n",
        "\n",
        "\n",
        "# Connection string\n",
        "cosmos_conn = config['cosmos_connection_string']\n",
        "cosmos_client = pymongo.MongoClient(cosmos_conn)\n",
        "\n",
        "# Database name\n",
        "DATABASE_NAME = \"ProductRecommendation\"\n",
        "db = cosmos_client[DATABASE_NAME]\n",
        "\n",
        "# Collection names\n",
        "actual_ratings = db[\"ActualRating\"]\n",
        "predicted_ratings = db[\"PredictedRating\"]\n",
        "product_catalog = db['ProductCollection']\n",
        "\n",
        "\n",
        "openai.api_type = config['openai_type']\n",
        "openai.api_key = config['openai_api_key']\n",
        "openai.api_base = config['openai_api_endpoint']\n",
        "openai.api_version = config['openai_api_version']\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_key=openai.api_key,\n",
        "    api_version=openai.api_version,\n",
        "    azure_endpoint = openai.api_base\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1711055304916
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def generate_embeddings(text):\n",
        "    try:\n",
        "        response = client.embeddings.create(\n",
        "            input=text, model=\"embeddings\") # need to read from config\n",
        "        \n",
        "        embeddings = response.data[0].embedding\n",
        "        \n",
        "        return embeddings\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1710462842770
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Simple function to assist with vector search\n",
        "def vector_search(query, collection, num_results=3):\n",
        "    query_embedding = generate_embeddings(query)\n",
        "    \n",
        "    pipeline = [\n",
        "        {\n",
        "            '$search': {\n",
        "                \"cosmosSearch\": {\n",
        "                    \"vector\": query_embedding,\n",
        "                    \"numLists\": 1,\n",
        "                    \"path\": \"Embedding\",\n",
        "                    \"k\": num_results \n",
        "                    #, \"efsearch\": 40 # optional for HNSW only \n",
        "                },\n",
        "                \"returnStoredSource\": True }},\n",
        "        {'$project': { 'similarityScore': { '$meta': 'searchScore' }, 'document' : '$$ROOT' } }\n",
        "    ]\n",
        "    results = collection.aggregate(pipeline)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "little test here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710462862519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "query = \"snowboard\"\n",
        "col = db['ProductCollection']\n",
        "results = vector_search(query,col, 10)\n",
        "\n",
        "print(\"\\nResults:\\n\")\n",
        "if True: \n",
        "    for result in results:\n",
        "        print(f\"Similarity Score: {result.get('similarityScore')}\")\n",
        "        document = result.get('document', {})\n",
        "        print(f\"Id: {document.get('Id')}\")\n",
        "        print(f\"Type: {document.get('Type')}\")\n",
        "        print(f\"Brand: {document.get('Brand')}\")\n",
        "        print(f\"Name: {document.get('Name')}\")\n",
        "else:\n",
        "    print(\"No results found. Please check your query or data setup.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# User search for products but exclude products of the same type as well as products already rated by user.\n",
        "# Example, if user searches for snowboard, don't return any more snowboards or products already rated by the user.\n",
        "\n",
        "def get_vector_based_recommendations_excluding_type(user_query, exclude_type, rated_products, num_results=10):\n",
        "    \n",
        "    query_embedding = generate_embeddings(user_query)\n",
        "\n",
        "    # Filter criteria to exclude the type of product and the products already rated by the user\n",
        "    filter_criteria = {\n",
        "        \"Type\": {\"$ne\": exclude_type}, \n",
        "        \"Id\": {\"$ne\": rated_products}\n",
        "    }\n",
        "\n",
        "    results = product_catalog.aggregate([\n",
        "        {\n",
        "            '$search': {\n",
        "                \"cosmosSearch\": {\n",
        "                    \"vector\": query_embedding,\n",
        "                    \"path\": \"Embedding\",\n",
        "                    \"k\": num_results,\n",
        "                    \"filter\": filter_criteria\n",
        "                },\n",
        "                \"returnStoredSource\": True\n",
        "            }},\n",
        "        {'$project': { 'similarityScore': { '$meta': 'searchScore' }, 'document' : '$$ROOT' }\n",
        "    }])\n",
        "\n",
        "    return list(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_rated_product_ids(user_id):\n",
        "    \"\"\"\n",
        "    Get products already purchased and rated by user.\n",
        "    Used to remove products from vector search results and recommendations.\n",
        "    \"\"\"\n",
        "    rated_product_ids = actual_ratings.find({\"UserId\": user_id}).distinct(\"ProductId\")\n",
        "    \n",
        "    return list(set(rated_product_ids))\n",
        "\n",
        "def get_better_recommendation(user_id, recommendations, num_results):\n",
        "    \"\"\"\n",
        "    This function filters a list of recommendations based on vector search. Then, it retrieves the user's predicted \n",
        "    ratings for products from a collection named predicted_ratings (trained using collaborative filtering). \n",
        "    The function matches these predictions with the initial list of recommendations, ensuring only items with a \n",
        "    predicted rating are considered. Finally, it returns the top num_results product IDs from this filtered list, \n",
        "    aiming to provide more personalized output.\n",
        "      \n",
        "    \"\"\"\n",
        "    # get the product ids from the recommendations\n",
        "    recommendation_ids = [rec['document']['Id'] for rec in recommendations]\n",
        "\n",
        "    # Get the predicted ratings for the user (this is a point read for all of the user's predicted ratings)\n",
        "    predicted_rating_products = predicted_ratings.find_one({\"UserId\": user_id})\n",
        "    \n",
        "    # Filter predictions to find those matching the recommended product IDs\n",
        "    filtered_predictions = [\n",
        "        prediction for prediction in predicted_rating_products['Predictions']\n",
        "        if prediction['ProductId'] in recommendation_ids\n",
        "    ]\n",
        "\n",
        "    # Return the Product IDs for the top N filtered predictions\n",
        "    return [prediction['ProductId'] for prediction in filtered_predictions[:num_results]]\n",
        "\n",
        "def recommend_products(user_query, user_id, num_results=3):\n",
        "    \"\"\"\n",
        "    Recommends products based on a user query, excluding products of the same type as the top result and\n",
        "    products the user has already rated.\n",
        "\n",
        "    This function identifies the type of this top result and retrieves a list of products the user has already rated. \n",
        "    With this information, it obtains a broader set of vector-based recommendations excluding products of the same type \n",
        "    as the top result and those already rated by the user. Finally, it narrows down these recommendations using the \n",
        "    get_better_recommendation function to select the top num_results items based on predicted user preferences.\n",
        "    \"\"\"\n",
        "    \n",
        "    top_result_cursor = vector_search(user_query, product_catalog, 1)\n",
        "    top_result = next(top_result_cursor, None)\n",
        "    top_product_type = top_result.get('document', {}).get('Type')  \n",
        "    \n",
        "    # get the products the user has already rated so we can exclude them in the vector search\n",
        "    rated_products = get_rated_product_ids(user_id)\n",
        "    \n",
        "    recommendations_vs = get_vector_based_recommendations_excluding_type(user_query, top_product_type, rated_products, 20)\n",
        "    \n",
        "    return get_better_recommendation(user_id, recommendations_vs, num_results), recommendations_vs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Function to recommend products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# actual_user_ids = [144, 496, 189, 232, 194, 950, 370, 980, 190, 404, 737, 959, 142, 795, 121, 743, 307, 365, 30, 726, 339, 536]\n",
        "user_query = \"i just bought a snowboard, what other products recommend me more products to buy?\"\n",
        "user_id = '189'\n",
        "user_id = int(user_id)\n",
        "num_results = 10\n",
        "\n",
        "# this needs to return an entire product, not just an id which then needs another query to the product collection\n",
        "recommended_products_id, vector_search_recommendations = recommend_products(user_query, user_id, num_results)\n",
        "\n",
        "print(\"---------Vector Search Results: --------\")\n",
        "for product in vector_search_recommendations[:num_results]:\n",
        "    print(f\"{product['document']['Id']}: {product['document']['Name']}\")\n",
        "\n",
        "print(\"\\n--------Model + VS Results: ---------\")\n",
        "for recommend_product in recommended_products_id:\n",
        "    product = (product_catalog.find_one({'Id':recommend_product}))\n",
        "    print(f\"{product.get('Id')}: {product.get('Name', 'No name')}, Price: {product.get('Price', 'No price')}\")\n",
        "\n",
        "\n",
        "rated_products = actual_ratings.find({'UserId': user_id})\n",
        "\n",
        "print(\"\\n-------Rated Products: --------\")\n",
        "for product in rated_products:\n",
        "    id = product['ProductId']\n",
        "    print(f\"{id}: {product_catalog.find_one({'Id':id}).get('Name')} | Rating: {product.get('Rating')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "My stuff below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predictions_from_current_product_page(user_id, current_product_id, num_results=3):\n",
        "    \"\"\"\n",
        "    This function recommends similar products predicted for this user excluding the current product.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get the predicted products for the user, limit results\n",
        "    user_predicted_products = predicted_ratings.find_one( \n",
        "        { \"UserId\": user_id },\n",
        "        {\"Predictions\": {\"$slice\": num_results}})\n",
        "\n",
        "    # Filter out the current product if exists and return a list of product ids\n",
        "    product_ids = [prediction['ProductId'] for prediction in user_predicted_products['Predictions'] \n",
        "        if prediction['ProductId'] != current_product_id]\n",
        "    \n",
        "    predicted_products = []\n",
        "\n",
        "    # loop through the product ids to look up the product details in the product_catalog maintaining the order of the product_ids\n",
        "    for product_id in product_ids:\n",
        "        product = product_catalog.find_one({\"Id\": product_id})\n",
        "        if product:\n",
        "            predicted_products.append(product)\n",
        "\n",
        "\n",
        "    # TO-DO: should do vector search on the current product versus just returning all the predicted products  \n",
        "\n",
        "    # Query the product_catalog and return the full product details\n",
        "    # predicted_products = product_catalog.find({\"Id\": {\"$in\": product_ids}}).limit(num_results)\n",
        "\n",
        "    predicted_products = list(predicted_products)\n",
        "\n",
        "    return predicted_products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predictions_from_vector_search(user_id, user_query, num_results=10):\n",
        "    \"\"\" \n",
        "    This function takes a user prompt search for products and returns products that are predicted for the user. \n",
        "    \"\"\"\n",
        "    \n",
        "    # Generate the embedding for the user query\n",
        "    query_embedding = generate_embeddings(user_query)\n",
        "\n",
        "    # Get the predicted products for the user\n",
        "    predicted_products = predicted_ratings.find_one( { \"UserId\": user_id } )\n",
        "\n",
        "    # Extract the ProductId from the Predictions array\n",
        "    product_ids = [prediction['ProductId'] for prediction in predicted_products['Predictions']]\n",
        "\n",
        "    # Filter criteria to include predicted products\n",
        "    filter_criteria = { \n",
        "        \"Id\": {\"$in\": product_ids}\n",
        "    }\n",
        "\n",
        "    results = product_catalog.aggregate([\n",
        "        {\n",
        "            '$search': {\n",
        "                \"cosmosSearch\": {\n",
        "                    \"vector\": query_embedding,\n",
        "                    \"path\": \"Embedding\",\n",
        "                    \"k\": num_results,\n",
        "                    \"filter\": filter_criteria\n",
        "                },\n",
        "                \"returnStoredSource\": True\n",
        "            }},\n",
        "        {'$project': { 'similarityScore': { '$meta': 'searchScore' }, 'document' : '$$ROOT' }\n",
        "    }])\n",
        "\n",
        "    predicted_products = list(results)\n",
        "\n",
        "    return predicted_products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------Vector Search Results: --------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "92: Blizzard Snowboard - 449.99\n",
            "73: Omni-Snow Dual Snowboard - 289.99\n",
            "43: Glacier Frost Snowboard - 419.99\n",
            "62: Shadow Black Snowboard - 379.0\n",
            "12: Powder Pro Snowboard - 399.0\n",
            "32: Cosmic Purple Snowboard - 419.99\n",
            "22: Venture 2022 Snowboard - 499.0\n",
            "39: Midnight Blue Goggles - 89.99\n",
            "42: Gravity 5000 All-Mountain Skis - 699.0\n",
            "72: GravityZone All-Mountain Skis - 699.0\n",
            "\n",
            "--------Current Page Results: ---------\n",
            "42: Gravity 5000 All-Mountain Skis - 699.0\n",
            "72: GravityZone All-Mountain Skis - 699.0\n",
            "92: Blizzard Snowboard - 449.99\n",
            "22: Venture 2022 Snowboard - 499.0\n",
            "62: Shadow Black Snowboard - 379.0\n",
            "32: Cosmic Purple Snowboard - 419.99\n",
            "12: Powder Pro Snowboard - 399.0\n",
            "43: Glacier Frost Snowboard - 419.99\n",
            "69: Expedition 200 GPS Navigator - 299.0\n"
          ]
        }
      ],
      "source": [
        "# actual_user_ids = [144, 496, 189, 232, 194, 950, 370, 980, 190, 404, 737, 959, 142, 795, 121, 743, 307, 365, 30, 726, 339, 536]\n",
        "# snowboards product_ids = 73, 5, 92, 83, 43, 12, 53, 62, 22\n",
        "user_query = \"i would like to buy a snowboard.\"\n",
        "user_id = '189'\n",
        "user_id = int(user_id)\n",
        "product_id = int(73) # TO-DO: find snowboards in the product catalog\n",
        "num_results = 10\n",
        "\n",
        "print(\"---------Vector Search Results: --------\")\n",
        "vector_search_with_predictions = predictions_from_vector_search(user_id, user_query, num_results)\n",
        "\n",
        "for product in vector_search_with_predictions:\n",
        "    print(f\"{product['document']['Id']}: {product['document']['Name']} - {product['document']['Price']}\")\n",
        "\n",
        "\n",
        "print(\"\\n--------Current Page Results: ---------\")\n",
        "on_page_predictions = predictions_from_current_product_page(user_id, product_id, num_results)\n",
        "\n",
        "for product in on_page_predictions:\n",
        "    print(f\"{product['Id']}: {product['Name']} - {product['Price']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
