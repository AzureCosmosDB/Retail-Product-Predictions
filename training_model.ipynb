{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS\n",
    "\n",
    "Alernative Least Squares\n",
    "\n",
    "https://medium.com/analytics-vidhya/model-based-recommendation-system-with-matrix-factorization-als-model-and-the-math-behind-fdce8b2ffe6d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "# be sure you have Java installed on your machine, https://www.java.com/en/download/\n",
    "! pip install pyspark  \n",
    "! pip install findspark\n",
    "\n",
    "! pip install pandas\n",
    "\n",
    "! pip install numpy\n",
    "! pip install pymongo\n",
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Java\\jdk-11\n"
     ]
    }
   ],
   "source": [
    "# Import the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "import os\n",
    "java_home = os.environ.get('JAVA_HOME')\n",
    "print(java_home)\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'ok': 1, 'n': 0}, acknowledged=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear out the predicted ratings collection\n",
    "\n",
    "# specify the name of the .env file name \n",
    "env_name = \"myconfig.env\" # following example.env template change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "# Azure Cosmos DB for MongoDB\n",
    "cosmos_conn = config['cosmos_connection_string']\n",
    "cosmos_client = pymongo.MongoClient(cosmos_conn)\n",
    "\n",
    "db = cosmos_client[\"ProductRecommendation\"]\n",
    "\n",
    "# specify the collection to put the predicted ratings in\n",
    "collection_predicted_rating = db['PredictedRating']\n",
    "\n",
    "# delete all documents in the collection to clear it out\n",
    "collection_predicted_rating.delete_many({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we start with here is a set of ratings that have been generated by users for products they have previously purchased.\n",
    "\n",
    "In this cell we read the dataset of user-item ratings from the file, Augmented Ratings, into a Pandas DataFrame, selecting only relevant columns (UserId, ProductId, Rating). This DataFrame is then converted into a Spark DataFrame, which is required to run the ALS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.executor.memory\",\"6g\")\n",
    "conf.set(\"spark.driver.memory\", \"6g\")\n",
    "conf.set(\"spark.driver.cores\", \"8\")\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Load the data from the json file\n",
    "full_pd_data = pd.read_json(\"./data/ratings/AugmentedRating.json\")  # TO-DO change the name of this file\n",
    "# just keep the required columns\n",
    "pd_data = full_pd_data[['UserId', 'ProductId', 'Rating']]\n",
    "# convert the data to spark dataframe, required to run the ALS model\n",
    "data = spark.createDataFrame(pd_data)\n",
    "# count the number of rows in the data\n",
    "data.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next need to split the dataset into training and testing sets with an 80-20 split, ensuring that models are trained on a majority of the data while having a separate subset for evaluation. We then cache both to improve performance by storing them in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[UserId: bigint, ProductId: bigint, Rating: double]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split to create train (80%) and test (20%) datasets\n",
    "train, test = data.randomSplit([0.8,0.2],10001)\n",
    "\n",
    "#cache the train and test datasets\n",
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to setup the ALS model, a collaborative filtering technique that will use the existing product ratings given by users over their purchased products to predict for each user the rating they might give to those products.\n",
    "\n",
    "Hyperparameter tuning is performed through a grid search over a defined parameter space combined with cross-validation to ensure the model's generalizability. The CrossValidator in PySpark automates this process, evaluating the model's performance using RMSE (Root Mean Square Error) metric. RMSE measures the average difference bewteen predicted and actual values in a dataset.\n",
    "\n",
    "After training, the best model is selected based on its performance, and its hyperparameters are printed for inspection. The model is then used to make predictions on the test set, and the RMSE of these predictions is calculated to assess the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the cross validator to tune the hyperparameters\n",
    "als = ALS(\n",
    "         userCol=\"UserId\", \n",
    "         itemCol=\"ProductId\",\n",
    "         ratingCol=\"Rating\", \n",
    "         coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 100]) \\\n",
    "            .addGrid(als.regParam, [.1]) \\\n",
    "            .addGrid(als.maxIter, [10]) \\\n",
    "            .build()\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "           metricName=\"rmse\", \n",
    "           labelCol=\"Rating\", \n",
    "           predictionCol=\"prediction\")\n",
    "\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3, parallelism = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model itself\n",
    "model = cv.fit(train)\n",
    "\n",
    "# return the best model from those that were trained above\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.3529248632229925. This is the average difference between the actual and predicted ratings. Lower values are better.\n"
     ]
    }
   ],
   "source": [
    "# now take the train data and calculate how well it does predicting the ratings.\n",
    "prediction = best_model.transform(test)\n",
    "rmse = evaluator.evaluate(prediction)\n",
    "print(f'RMSE = {rmse}. This is the average difference between the actual and predicted ratings. Lower values are better.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the vectors for each user and product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector to describe what user attributes are important in making a predication for a rating\n",
    "user_v = best_model.userFactors.collect()[0].features\n",
    "\n",
    "# vector to describe what product attributes are important in making a prediction for a rating\n",
    "item_v = best_model.itemFactors.collect()[0].features\n",
    "\n",
    "print('User Vector: ' + str(user_v))\n",
    "print('Product Vector: ' + str(item_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The **dot product** of a user and item vector is computed as an example, showcasing how to predict a user's rating for a specific item based on their latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.054752382127225"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot((user_v),(item_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of calculating dot product each time we need a prediction, to make our ecommerce app as fast as possible, we are going to first generate all of the recommendations for all users and all products. Then save these in Azure Cosmos DB for MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line uses the best model obtained from the tuning process to generate recommendations for all users.\n",
    "val_recommendations = best_model.recommendForAllUsers(10001)\n",
    "rec_sys_final_predictions = []\n",
    "\n",
    "for user in val_recommendations.collect():\n",
    "    to_insert = {}\n",
    "    to_insert['UserId'] = user.UserId\n",
    "    to_insert['Predictions'] = [{\"ProductId\": user.recommendations[x].ProductId, \"rating\": user.recommendations[x].rating} for x in range(len(user.recommendations))]\n",
    "    rec_sys_final_predictions.append(to_insert)\n",
    "\n",
    "#collection_predicted_rating.insert_many(rec_sys_final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|UserId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{42, 9.025747}, ...|\n",
      "|    12|[{42, 8.798659}, ...|\n",
      "|    22|[{42, 8.528533}, ...|\n",
      "|    26|[{42, 7.185434}, ...|\n",
      "|    27|[{42, 7.648633}, ...|\n",
      "|    28|[{42, 8.761372}, ...|\n",
      "|    31|[{42, 8.889992}, ...|\n",
      "|    34|[{72, 7.499691}, ...|\n",
      "|    44|[{72, 7.245907}, ...|\n",
      "|    47|[{72, 7.309139}, ...|\n",
      "|    52|[{42, 7.16784}, {...|\n",
      "|    53|[{42, 9.005878}, ...|\n",
      "|    65|[{72, 7.3831053},...|\n",
      "|    76|[{42, 8.893301}, ...|\n",
      "|    78|[{72, 7.526666}, ...|\n",
      "|    81|[{42, 9.012387}, ...|\n",
      "|    85|[{42, 7.038196}, ...|\n",
      "|    91|[{42, 7.403313}, ...|\n",
      "|    93|[{42, 8.873975}, ...|\n",
      "|   101|[{42, 7.1201096},...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_recommendations.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
