{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "! pip install numpy\n",
        "! pip install openai==1.2.3\n",
        "! pip install pymongo\n",
        "! pip install python-dotenv\n",
        "! pip install azure-core\n",
        "! pip install azure-cosmos\n",
        "! pip install tenacity\n",
        "\n",
        "! pip install scikit-surprise\n",
        "! pip install scikit-learn\n",
        "! pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1712007427712
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import openai\n",
        "import pymongo\n",
        "\n",
        "from dotenv import dotenv_values\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "env_name = \"myconfig.env\" \n",
        "config = dotenv_values(env_name)\n",
        "\n",
        "\n",
        "# Connection string\n",
        "mongo_conn = config['cosmos_connection_string']\n",
        "mongo_client = pymongo.MongoClient(mongo_conn)\n",
        "\n",
        "# Database name\n",
        "DATABASE_NAME = \"ProductRecommendation\"\n",
        "db = mongo_client[DATABASE_NAME]\n",
        "\n",
        "# Collection names\n",
        "collection_actual_rating = db[\"ActualRating\"]\n",
        "collection_predicted_rating = db[\"PredictedRating\"]\n",
        "collection_product = db['ProductCollection']\n",
        "\n",
        "\n",
        "openai.api_type = config['openai_type']\n",
        "openai.api_key = config['openai_api_key']\n",
        "openai.api_base = config['openai_api_endpoint']\n",
        "openai.api_version = config['openai_api_version']\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_key=openai.api_key,\n",
        "    api_version=openai.api_version,\n",
        "    azure_endpoint = openai.api_base\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711055304916
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def generate_embeddings(text):\n",
        "    try:\n",
        "        response = client.embeddings.create(\n",
        "            input=text, model=\"embeddings\") # need to read from config\n",
        "        \n",
        "        embeddings = response.data[0].embedding\n",
        "        \n",
        "        return embeddings\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "embeddings = generate_embeddings(\"i just bought a snowboard, recommend me more products to buy?\")\n",
        "\n",
        "if embeddings is not None:\n",
        "    print(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1710462842770
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Simple function to assist with vector search\n",
        "def vector_search(query, collection, num_results=3):\n",
        "    query_embedding = generate_embeddings(query)\n",
        "    embeddings_list = []\n",
        "    pipeline = [\n",
        "        {\n",
        "            '$search': {\n",
        "                \"cosmosSearch\": {\n",
        "                    \"vector\": query_embedding,\n",
        "                    \"numLists\": 1,\n",
        "                    \"path\": \"Embedding\",\n",
        "                    \"k\": num_results \n",
        "                    #, \"efsearch\": 40 # optional for HNSW only \n",
        "                },\n",
        "                \"returnStoredSource\": True }},\n",
        "        {'$project': { 'similarityScore': { '$meta': 'searchScore' }, 'document' : '$$ROOT' } }\n",
        "    ]\n",
        "    results = collection.aggregate(pipeline)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "little test here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1710462862519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "query = \"snowboard\"\n",
        "col = db['ProductCollection']\n",
        "results = vector_search(query,col, 5)\n",
        "\n",
        "print(\"\\nResults:\\n\")\n",
        "if True: \n",
        "    for result in results:\n",
        "        print(f\"Similarity Score: {result.get('similarityScore')}\")\n",
        "        document = result.get('document', {})\n",
        "        print(f\"Id: {document.get('Id')}\")\n",
        "        print(f\"Type: {document.get('Type')}\")\n",
        "        print(f\"Brand: {document.get('Brand')}\")\n",
        "        print(f\"Name: {document.get('Name')}\")\n",
        "else:\n",
        "    print(\"No results found. Please check your query or data setup.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluates the predicted rating vs actual (enhanced) rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# why are we doing this?\n",
        "\n",
        "\n",
        "collection_actual_rating.delete_many({})\n",
        "# Load actual ratings data\n",
        "with open(\"./data/ratings/actualRatings.json\", \"r\") as f:\n",
        "    actual_rating = json.load(f)\n",
        "\n",
        "# Insert data into the ActualRating collection\n",
        "result = collection_actual_rating.insert_many(actual_rating)\n",
        "\n",
        "print(f\"Number of data points added: {len(result.inserted_ids)} in ActualRating\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Logic: \n",
        "Using Vector similarity search, look up top 10 products, based on the query\n",
        "    Exclude items that have the same type as the top result (So if the user buys a snowboard, it doesnt recommend any more snowboards) and products already rated by the user.\n",
        "\n",
        "Now feed in these top 10 products in the recommendation model to recommend me top 3 products that user should buy based on the products they have rated before (not in the actualRatings collection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_vector_based_recommendations_excluding_type(user_query, exclude_type, rated_products, num_results=10):\n",
        "    query_embedding = generate_embeddings(user_query)\n",
        "    if query_embedding is None:\n",
        "        return []\n",
        "\n",
        "    filter_criteria = {\n",
        "        \"Type\": {\"$ne\": exclude_type}, \n",
        "        \"Id\": {\"$ne\": rated_products}\n",
        "    }\n",
        "\n",
        "    results = collection_product.aggregate([\n",
        "        {\n",
        "            '$search': {\n",
        "                \"cosmosSearch\": {\n",
        "                    \"vector\": query_embedding,\n",
        "                    \"path\": \"Embedding\",\n",
        "                    \"k\": num_results,\n",
        "                    \"filter\": filter_criteria\n",
        "                },\n",
        "                \"returnStoredSource\": True\n",
        "            }},\n",
        "        {'$project': { 'similarityScore': { '$meta': 'searchScore' }, 'document' : '$$ROOT' }\n",
        "    }])\n",
        "\n",
        "    return list(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- get_rated_product_ids(user_id): This function fetches and returns a list of product IDs that the specified user has already rated. It queries a database collection named collection_actual_rating to find all ratings associated with the user's ID and extracts distinct product IDs from those ratings. The purpose is to identify products the user has interacted with, ensuring the recommendation system does not suggest items the user has already reviewed.\n",
        "\n",
        "- get_better_recommendation(user_id, recommendations, num_results): This function filters a list of recommendations based on vector search. Then, it retrieves the user's predicted ratings for products from a collection named collection_predicted_rating (trained using collaborative filtering). The function matches these predictions with the initial list of recommendations, ensuring only items with a predicted rating are considered. Finally, it returns the top num_results product IDs from this filtered list, aiming to provide more personalized output.\n",
        "\n",
        "- recommend_products(user_query, user_id, num_results=3): It identifies the type of this top result and retrieves a list of products the user has already rated. With this information, it obtains a broader set of vector-based recommendations excluding products of the same type as the top result and those already rated by the user. Finally, it narrows down these recommendations using the get_better_recommendation function to select the top num_results items based on predicted user preferences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_rated_product_ids(user_id):\n",
        "    \"\"\"\n",
        "    Retrieves a set of product IDs that the user hasn't rated yet by querying the actual ratings collection.\n",
        "    \"\"\"\n",
        "    rated_product_ids = collection_actual_rating.find({\"UserId\": user_id}).distinct(\"ProductId\")\n",
        "    return list(set(rated_product_ids))\n",
        "\n",
        "def get_better_recommendation(user_id, recommendations, num_results):\n",
        "    recommendation_ids = [rec['document']['Id'] for rec in recommendations]\n",
        "    predicted_rating_products = collection_predicted_rating.find_one({\"UserId\": user_id})\n",
        "    \n",
        "    # Filter predictions to find those matching the recommended product IDs\n",
        "    filtered_predictions = [\n",
        "    prediction for prediction in predicted_rating_products['Predictions']\n",
        "    if prediction['ProductId'] in recommendation_ids\n",
        "    ]\n",
        "\n",
        "    # Return the Product IDs for the top N filtered predictions\n",
        "    return [prediction['ProductId'] for prediction in filtered_predictions[:num_results]]\n",
        "\n",
        "def recommend_products(user_query, user_id, num_results=3):\n",
        "    \"\"\"\n",
        "    Recommends products based on a user query, excluding products of the same type as the top result and\n",
        "    products the user has already rated.\n",
        "    \"\"\"\n",
        "    top_result_cursor = vector_search(user_query, collection_product, 1)\n",
        "    top_result = next(top_result_cursor, None)  \n",
        "    top_product_type = top_result.get('document', {}).get('Type')  \n",
        "    rated_products = get_rated_product_ids(user_id)\n",
        "    recommendations_vs = get_vector_based_recommendations_excluding_type(user_query, top_product_type, rated_products, 20)\n",
        "    \n",
        "    return get_better_recommendation(user_id, recommendations_vs, num_results), recommendations_vs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Function to recommend products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------Vector Search Results: --------\n",
            "55: Vigor 2.0 Insulated Jacket\n",
            "71: Explorer Frost Boots\n",
            "47: Edge Pro Ice Axe\n",
            "8: Frostbite Insulated Jacket\n",
            "79: Everest Insulated Jacket\n",
            "15: Summit Pro Insulated Jacket\n",
            "28: Alpine Peak Down Jacket\n",
            "2: Summit Pro Harness\n",
            "49: Arctic Shield Insulated Jacket\n",
            "89: Summit Pro Down Jacket\n",
            "\n",
            "--------Model + VS Results: ---------\n",
            "88: Alpine AlpinePack Backpack, Price: 129.0\n",
            "7: Explorer 45L Backpack, Price: 149.99\n",
            "28: Alpine Peak Down Jacket, Price: 249.99\n",
            "55: Vigor 2.0 Insulated Jacket, Price: 189.99\n",
            "15: Summit Pro Insulated Jacket, Price: 249.99\n",
            "65: Sprint PRO Carbon Cycling Helmet, Price: 179.99\n",
            "49: Arctic Shield Insulated Jacket, Price: 169.99\n",
            "71: Explorer Frost Boots, Price: 149.99\n",
            "89: Summit Pro Down Jacket, Price: 239.99\n",
            "8: Frostbite Insulated Jacket, Price: 179.99\n",
            "\n",
            "-------Rated Products: --------\n"
          ]
        }
      ],
      "source": [
        "# actual_user_ids = [144, 496, 189, 232, 194, 950, 370, 980, 190, 404, 737, 959, 142, 795, 121, 743, 307, 365, 30, 726, 339, 536]\n",
        "user_query = \"i just bought a snowboard, what other products recommend me more products to buy?\"\n",
        "user_id = '189'\n",
        "user_id = int(user_id)\n",
        "num_results = 10\n",
        "recommended_products_id, vector_search_recommendations = recommend_products(user_query, user_id, num_results)\n",
        "\n",
        "print(\"---------Vector Search Results: --------\")\n",
        "for product in vector_search_recommendations[:num_results]:\n",
        "    print(f\"{product['document']['Id']}: {product['document']['Name']}\")\n",
        "\n",
        "print(\"\\n--------Model + VS Results: ---------\")\n",
        "for recommend_product in recommended_products_id:\n",
        "    product = (collection_product.find_one({'Id':recommend_product}))\n",
        "    print(f\"{product.get('Id')}: {product.get('Name', 'No name')}, Price: {product.get('Price', 'No price')}\")\n",
        "\n",
        "\n",
        "rated_products = collection_actual_rating.find({'UserId': user_id})\n",
        "print(\"\\n-------Rated Products: --------\")\n",
        "for product in rated_products:\n",
        "    id = product['ProductId']\n",
        "    print(f\"{id}: {collection_product.find_one({'Id':id}).get('Name')} | Rating: {product.get('Rating')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
