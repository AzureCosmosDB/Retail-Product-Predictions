{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS\n",
    "\n",
    "Alernative Least Squares\n",
    "\n",
    "https://medium.com/analytics-vidhya/model-based-recommendation-system-with-matrix-factorization-als-model-and-the-math-behind-fdce8b2ffe6d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "\n",
    "# Java is required local install.\n",
    "# Java: https://www.java.com/en/download/\n",
    "# Spark: https://spark.apache.org/downloads.html\n",
    "\n",
    "! pip install pyspark  \n",
    "! pip install findspark\n",
    "\n",
    "! pip install pandas\n",
    "! pip install numpy\n",
    "! pip install python-dotenv\n",
    "\n",
    "! pip install azure-cosmos\n",
    "! pip install azure-core\n",
    "! pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "from uuid import uuid4 as GUID\n",
    "\n",
    "from azure.cosmos.aio import CosmosClient\n",
    "from azure.cosmos import PartitionKey, exceptions\n",
    "from azure.cosmos import ThroughputProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"myconfig.env\" \n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "# Cosmos Client\n",
    "cosmos_endpoint = config['cosmos_endpoint']\n",
    "cosmos_key = config['cosmos_key']\n",
    "database_name = config['cosmos_database']\n",
    "actual_ratings_name = config['cosmos_actual_ratings']\n",
    "predicted_ratings_name = config['cosmos_predicted_ratings']\n",
    "product_catalog_name = config['cosmos_product_catalog']\n",
    "\n",
    "cosmos_client = CosmosClient(cosmos_endpoint, cosmos_key)\n",
    "\n",
    "database = cosmos_client.get_database_client(database_name)\n",
    "predicted_ratings_container = database.get_container_client(predicted_ratings_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only execute this cell if you need to recreate the predicted ratings collection (uncomment the delete_container line)\n",
    "async def recreate_predicted_ratings_collection():\n",
    "    \n",
    "    # Database\n",
    "    database = await cosmos_client.create_database_if_not_exists(id=database_name)\n",
    "\n",
    "    # Commented for extra protection from deletion\n",
    "    # database.delete_container(predicted_ratings_name)\n",
    "\n",
    "    # Ratings Data Collections\n",
    "    await database.create_container_if_not_exists(\n",
    "        id=predicted_ratings_name, \n",
    "        partition_key=PartitionKey(path=\"/UserId\"),\n",
    "        offer_throughput=ThroughputProperties(auto_scale_max_throughput=4000))\n",
    "    \n",
    "await recreate_predicted_ratings_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we start with here is a set of ratings that have been generated by users for products they have previously purchased.\n",
    "\n",
    "In this cell we read the dataset of user-item ratings from the file, Augmented Ratings, into a Pandas DataFrame, selecting only relevant columns (UserId, ProductId, Rating). This DataFrame is then converted into a Spark DataFrame, which is required to run the ALS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Retail-Product-Predictions\") \\\n",
    "    .config(\"spark.master\", \"local\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.driver.cores\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the data from the json file\n",
    "full_pd_data = pd.read_json(\"./data/ratings/actualRatings.json\")\n",
    "\n",
    "# just keep the required columns\n",
    "pd_data = full_pd_data[['UserId', 'ProductId', 'Rating']]\n",
    "\n",
    "# convert the data to spark dataframe, required to run the ALS model\n",
    "data = spark.createDataFrame(pd_data)\n",
    "\n",
    "# count the number of rows in the data\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next need to split the dataset into training and testing sets with an 80-20 split, ensuring that models are trained on a majority of the data while having a separate subset for evaluation. We then cache both to improve performance by storing them in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[UserId: bigint, ProductId: bigint, Rating: double]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split to create train (80%) and test (20%) datasets\n",
    "train, test = data.randomSplit([0.8,0.2],10001)\n",
    "\n",
    "#cache the train and test datasets\n",
    "train.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to setup the ALS model, a collaborative filtering technique that will use the existing product ratings given by users over their purchased products to predict for each user the rating they might give to those products.\n",
    "\n",
    "Hyperparameter tuning is performed through a grid search over a defined parameter space combined with cross-validation to ensure the model's generalizability. The CrossValidator in PySpark automates this process, evaluating the model's performance using RMSE (Root Mean Square Error) metric. RMSE measures the average difference bewteen predicted and actual values in a dataset.\n",
    "\n",
    "After training, the best model is selected based on its performance, and its hyperparameters are printed for inspection. The model is then used to make predictions on the test set, and the RMSE of these predictions is calculated to assess the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the cross validator to tune the hyperparameters\n",
    "als = ALS(\n",
    "         userCol=\"UserId\", \n",
    "         itemCol=\"ProductId\",\n",
    "         ratingCol=\"Rating\", \n",
    "         coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 100]) \\\n",
    "            .addGrid(als.regParam, [.1]) \\\n",
    "            .addGrid(als.maxIter, [10]) \\\n",
    "            .build()\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "           metricName=\"rmse\", \n",
    "           labelCol=\"Rating\", \n",
    "           predictionCol=\"prediction\")\n",
    "\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3, parallelism = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model itself. This takes 1-2 minutes\n",
    "model = cv.fit(train)\n",
    "\n",
    "# return the best model from those that were trained above\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.35502647060722764. This is the average difference between the actual and predicted ratings. Lower values are better.\n"
     ]
    }
   ],
   "source": [
    "# now take the train data and calculate how well it does predicting the ratings.\n",
    "prediction = best_model.transform(test)\n",
    "rmse = evaluator.evaluate(prediction)\n",
    "print(f'RMSE = {rmse}. This is the average difference between the actual and predicted ratings. Lower values are better.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the vectors for each user and product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector to describe what user attributes are important in making a predication for a rating\n",
    "user_v = best_model.userFactors.collect()[0].features\n",
    "\n",
    "# vector to describe what product attributes are important in making a prediction for a rating\n",
    "item_v = best_model.itemFactors.collect()[0].features\n",
    "\n",
    "print('User Vector: ' + str(user_v))\n",
    "print('Product Vector: ' + str(item_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The **dot product** of a user and item vector is computed as an example, showcasing how to predict a user's rating for a specific item based on their latent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.048279562412358"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot((user_v),(item_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of calculating dot product each time we need a prediction, to make our ecommerce app as fast as possible, we are going to first generate all of the recommendations for all users and all products. Then save these in Azure Cosmos DB for NoSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted ratings added: 2080\n",
      "+------+--------------------+\n",
      "|UserId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{42, 9.012838}, ...|\n",
      "|     2|[{72, 7.738515}, ...|\n",
      "|     3|[{42, 8.855551}, ...|\n",
      "|     4|[{72, 7.276962}, ...|\n",
      "|     5|[{42, 7.388352}, ...|\n",
      "|     6|[{42, 8.582646}, ...|\n",
      "|     7|[{72, 7.672081}, ...|\n",
      "|     8|[{42, 8.615616}, ...|\n",
      "|     9|[{72, 7.3360405},...|\n",
      "|    10|[{42, 8.526747}, ...|\n",
      "|    11|[{72, 8.249162}, ...|\n",
      "|    12|[{42, 8.783088}, ...|\n",
      "|    13|[{42, 7.350541}, ...|\n",
      "|    14|[{72, 7.131305}, ...|\n",
      "|    15|[{72, 8.900069}, ...|\n",
      "|    16|[{72, 8.677717}, ...|\n",
      "|    17|[{42, 8.914647}, ...|\n",
      "|    18|[{42, 8.335895}, ...|\n",
      "|    19|[{42, 8.984622}, ...|\n",
      "|    20|[{42, 7.158357}, ...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def generated_predicted_ratings():\n",
    "    \n",
    "    final_predictions = []\n",
    "    \n",
    "    # This line uses the best model obtained from the tuning process to generate recommendations for all users.\n",
    "    predicted_recommendations = best_model.recommendForAllUsers(10001)\n",
    "\n",
    "    # Create a json object with the recommendations for each product for each user\n",
    "    for user in predicted_recommendations.collect():\n",
    "        user_prediction = {}\n",
    "        user_prediction['id'] = str(user.UserId)\n",
    "        user_prediction['UserId'] = str(user.UserId)\n",
    "        user_prediction['Predictions'] = [ { \"ProductId\": str(user.recommendations[x].ProductId), \"Rating\": user.recommendations[x].rating } for x in range(len(user.recommendations)) ]\n",
    "        final_predictions.append(user_prediction)\n",
    "\n",
    "    i=0\n",
    "    # Insert these into the predicted ratings container\n",
    "    for item in final_predictions:\n",
    "        i+=1\n",
    "        await predicted_ratings_container.create_item(item)\n",
    "\n",
    "    print(f\"Number of predicted ratings added: {i}\")\n",
    "\n",
    "    # Display the precited recommendations\n",
    "    predicted_recommendations.show()\n",
    "\n",
    "await generated_predicted_ratings()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
